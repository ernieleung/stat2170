---
title: "STAT2170 Assignment"
author: Ernie Leung (47234083)
output: 
  pdf_document:
    toc: true
    number_sections: true
    fig_caption: true
    keep_tex: true
date: "2025-05-22"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

\newpage

# Question 1

```{r q1}
sleep <- read.csv("sleep.csv")
```

## (a) Plot & Correlation Matrix of Data

```{r st, fig.height = 4, fig.width = 4}
# Plots
par(mfrow = c(2, 2))
plot(sleep$age, sleep$ai, main = "ai vs age", xlab = "age", ylab = "ai")
plot(sleep$bmi, sleep$ai, main = "AI vs BMI", xlab = "age", ylab = "ai")
plot(sleep$neck_size, sleep$ai, main = "ai vs neck size", xlab = "neck_size", ylab = "ai")
plot(sleep$sbp, sleep$ai, main = "ai vs sbp", xlab = "sbp", ylab = "ai")

# Correlation matrix
cor(sleep)
```

## (b) Fitting Model & 95% Confidence Interval

```{r q1b}
# Fit the full linear regression model
fm <- lm(ai ~ age + bmi + neck_size + sbp, data = sleep)
summary(fm)
```

Next, we extract a **95% confidence interval** to estimate impact of
`neck_size` on `ai`.

```{r q1bneck}
confint(fm, "neck_size", level = 0.95)
```

The coefficient for neck_size tells us how the arousal index (ai) is
expected to change when neck size increases by 1 cm, in this case it is
statistically significant (p = 0.003), which indicates that neck size
effects the arousal index.

## (c) Mathematical Model

The multiple linear regression model for this study is given by: $$
\text{ai}_i = \beta_0 + \beta_1 \cdot \text{age}_i + \beta_2 \cdot \text{bmi}_i + \beta_3 \cdot \text{neck\_size}_i + \beta_4 \cdot \text{sbp}_i + \varepsilon_i
$$ **Where:**

-   $\text{ai}_i$: logged arousal index (ai) for the response variable
    $i^{th}$ patient\
-   $\beta_0$: intercept, the expected arousal index when all predictors
    are 0\

## (c) Hypothesis for the Overall F-Test

To test whether the predictors (age, bmi, neck_size, sbp) are associated
with the response variable `ai`, we hypothesize:

-   **Null Hypothesis** $H_0$: $$
    \beta_1 = \beta_2 = \beta_3 = \beta_4 = 0
    $$ Meaningg none of the predictors have a linear relationship with
    `ai`.

-   **Alternative Hypothesis** $H_1$: $$
    \text{At least one } \beta_j \ne 0 \quad \text{for } j = 1, 2, 3, 4
    $$ Meaning at least one predictor is linearly related to `ai`.

## (c) ANOVA Table for the Full Model

```{r q1anova}
fm <- lm(ai ~ age + bmi + neck_size + sbp, data = sleep)

anova(fm)
```

## (c) Null Distribution of the Test Statistic

The test statistic used in the overall regression F test follows an F
distribution under the null hypothesis:

$$
F \sim F_{4, 122 - 4 - 1} = F_{4,117}
$$

## (c) P-Value

We compute the p-value associated with the overall F test using the
`pf()` function:

```{r q1cpv}
# F-Statistic and degrees of freedom
f_stat <- summary(fm)$fstatistic
fvalue <- f_stat[1]
df1 <- f_stat[2]
df2 <- f_stat[3]

# P-Value
pf(fvalue, df1, df2, lower.tail = FALSE)
```

## (c) Conclusion

**Statistical Conclusion:**

Since the p-value is very small (typically \< 0.05), we reject the null
hypothesis ($H_0$). This result suggests that at least one of the
predictors (age, BMI, neck size, or sbp) has a significant relationship
with the arousal index (ai).

**Contextual Conclusion:**

There is sufficient evidence to conclude that one or more of the
variables are significant predictors of the arousal index in patients
suspected of having Obstructive Sleep Apnoea.

## (d) Model Validation

We check the standard assumptions of the linear regression model:

```{r q1d, fig.height = 5, fig.width = 5}
# Plots
par(mfrow = c(2, 2))
plot(fm)
```

Based on these plots, the assumptions (linearity, normality) of linear
regression appear to be reasonably satisfied. Therefore, the full
regression model is appropriate for explaining variation in the arousal
index.

## (e) $R^2$ Value

We extract the $R^2$ value from the full model to assess how well the
model explains variation in the response variable.

```{r q1rsquared}
# R-squared value
summary(fm)$r.squared
```

## (f) Finding the best multiple regression model

We compare models by examining their adjusted $R^2$ values and the
significance of individual predictors.

```{r q1f}
fm <- lm(ai ~ age + bmi + neck_size + sbp, data = sleep)
adjr2_full <- summary(fm)$adj.r.squared
reduced_model <- lm(ai ~ age + bmi + neck_size, data = sleep)
reduced_adjr2 <- summary(reduced_model)$adj.r.squared

c(
  "Full model Adjusted R^2" = adjr2_full,
  "Reduced model Adjusted R^2" = reduced_adjr2
)

final_model <- if (reduced_adjr2 > adjr2_full) reduced_model else fm
print(summary(final_model))
```

## (g) Comments on $R^2$ and Adjusted $R^2$

```{r q1g}
r2_full <- summary(fm)$r.squared
adjr2_full <- summary(fm)$adj.r.squared
r2_final <- summary(final_model)$r.squared
adjr2_final <- summary(final_model)$adj.r.squared

c(
  "Full model R^2" = r2_full,
  "Full model Adjusted R^2" = adjr2_full,
  "Final model R^2" = r2_final,
  "Final model Adjusted R^2" = adjr2_final
)

```

This small decrease in both values shows that `sbp` contributes very
minor to the model, and is insigificant. The adjusted $R^2$ which takes
into the factor of model complexity decreased only slightly suggesting
that the Adjusted $R^2$ model still performs reasonably well. Therefore,
adjusted $R^2$ provides a better basis for comparing models with
different numbers of predictors.

\newpage

# Question 2

```{r q2}
energy <- read.csv("energy.csv")
```

## (a) Balanced vs Unbalanced Design

A balanced design means that each combination of the factor (`range` &
`factor`) have the **same amout of observations**. Whilst the latter
does not.

```{r q2ch}
# Table to check the num of observations per group
table(energy$range, energy$menu)
```

## (b) Preliminary Graphs

We construct two plots to examine how consumption varies by range and
menu. \### Plot 1: Boxplot of Consumption by Range

```{r q2rangeboxplot, fig.width = 7, fig.height = 3}
boxplot(consumption ~ range, data = energy,
        main = "Energy Consumption by Range",
        xlab = "Range",
        ylab = "Consumption",
        col = "blue")
```

## (c) Full Interaction Model

$$
Y_{ijk} = \mu + \alpha_i + \beta_j + (\alpha\beta)_{ij} + \varepsilon_{ijk}
$$

**Where:**

-   $Y_{ijk}$: observed response (energy consumption) for the $k^{th}$
    replicate under the $i^{th}$ range and $j^{th}$ menu
-   $\mu$: overall mean energy consumption
-   $\alpha_i$: effect of the $i^{th}$ **range** (for
    $i = 1, 2, 3, 4, 5$)
-   $\beta_j$: effect of the $j^{th}$ **menu** (for $j = 1, 2$)
-   $(\alpha\beta)_{ij}$: **interaction effect** between the $i^{th}$
    range and $j^{th}$ menu
-   $\varepsilon_{ijk}$: random error term $$
    \varepsilon_{ijk} \sim N(0, \sigma^2)
    $$

This model tests the main effects of `range` and `menu` and the
interaction between them.

## (d) Analysing the Data

We use a two-way ANOVA model with `range` and `menu` to see if there is
a significant effect on energy consumption.

### Hypotheses

We test the following hypotheses:

-   **Main effect of range**

    $H_0: \alpha_1 = \alpha_2 = \dots = \alpha_5 = 0$\
    $H_1:$ At least one $\alpha_i \ne 0$

-   **Main effect of menu**

    $H_0: \beta_1 = \beta_2 = 0$\
    $H_1:$ At least one $\beta_j \ne 0$

-   **Interaction effect**

    $H_0: (\alpha\beta)_{ij} = 0 \text{ for all } i, j$\
    $H_1:$ At least one interaction term $\ne 0$

------------------------------------------------------------------------

### Performing the Analysis

```{r q2twoanova}
energy$range <- factor(energy$range) #specify factors
energy$menu <- factor(energy$menu)

aov(consumption ~ range * menu, data = energy)
```

### Conclusion

The ANOVA results show that the interaction between range and menu is
**NOT significant** (where p \> 0.05) so we must interpret the effects,
of which:

-   The `range` has a significant effect on energy consumption (p \<
    0.01), while the `menu` does not (p \> 0.05).

Therefore, energy consumption depends on the range used, regardless of
menu.
